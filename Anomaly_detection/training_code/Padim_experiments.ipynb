{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: fit  \n",
    "Backbone: ResNet18  \n",
    "Num_features: 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 11.7 M | train\n",
      "---------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.758    Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "81        Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 81 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8da270d0144828ba9603ff20780c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a05530de754ec48517fe3ce7d5b117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/resnet18.pth\", map_location='cuda')\n",
    "custom_backbone = models.resnet18()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 100,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.fit(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7151896b33e24600a788e46eede8c111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7072105407714844     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.924124538898468     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9388129711151123     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7383236289024353     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7072105407714844    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.924124538898468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9388129711151123    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7383236289024353    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7072105407714844,\n",
       "  'image_F1Score': 0.924124538898468,\n",
       "  'pixel_AUROC': 0.9388129711151123,\n",
       "  'pixel_F1Score': 0.7383236289024353}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42   \n",
    ")\n",
    "\n",
    "engine.test(model=model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: train  \n",
    "Backbone: ResNet18  \n",
    "Num_features: 300    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 11.7 M | train\n",
      "---------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.758    Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "81        Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 81 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1fd381dd774095a9f8f4a2316c409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96e694b6d124b1ca46b88b126a4398f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ed983e64b34a51a218ce4f388c53d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7176539301872253     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9245837330818176     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9420230984687805     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7568559646606445     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7176539301872253    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9245837330818176    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9420230984687805    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7568559646606445    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7176539301872253,\n",
       "  'image_F1Score': 0.9245837330818176,\n",
       "  'pixel_AUROC': 0.9420230984687805,\n",
       "  'pixel_F1Score': 0.7568559646606445}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=4,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/resnet18.pth\", map_location='cuda')\n",
    "custom_backbone = models.resnet18()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: fit  \n",
    "Backbone: ResNet50  \n",
    "Num_features: 100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 25.6 M | train\n",
      "---------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "172       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 172 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fba8f5b7c014d849f7e456d695ae1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e957c9089c4b00929d452685fd5bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/resnet50.pth\", map_location='cuda')\n",
    "custom_backbone = models.resnet50()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 100,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.fit(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8553acb59944018d59b3eb78547e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.707317054271698     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9159248471260071     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9453808069229126     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7531141042709351     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.707317054271698    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9159248471260071    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9453808069229126    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7531141042709351    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.707317054271698,\n",
       "  'image_F1Score': 0.9159248471260071,\n",
       "  'pixel_AUROC': 0.9453808069229126,\n",
       "  'pixel_F1Score': 0.7531141042709351}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42   \n",
    ")\n",
    "\n",
    "engine.test(model=model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: train  \n",
    "Backbone: ResNet50  \n",
    "Num_features: 300    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 25.6 M | train\n",
      "---------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "172       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 172 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9c326f9b484cb0b48923e2eeaf386f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb58ebc3a5e2479badbc10a34bbd9b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b46f61c31c41eca72899a9bc8f8e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7069105505943298     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9211045503616333     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9515622854232788     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7787567377090454     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7069105505943298    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9211045503616333    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9515622854232788    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7787567377090454    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7069105505943298,\n",
       "  'image_F1Score': 0.9211045503616333,\n",
       "  'pixel_AUROC': 0.9515622854232788,\n",
       "  'pixel_F1Score': 0.7787567377090454}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/resnet50.pth\", map_location='cuda')\n",
    "custom_backbone = models.resnet50()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: train  \n",
    "Backbone: WideResNet50_2  \n",
    "Num_features: 100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "172       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 172 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578224d26e6948d0a919560899766242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3204b0a0fb834dd9917116066730079f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db09b491be9475e892ea4dda7ea4052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6878243088722229     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9147442579269409     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.950670599937439     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7730256915092468     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6878243088722229    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9147442579269409    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.950670599937439    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7730256915092468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.6878243088722229,\n",
       "  'image_F1Score': 0.9147442579269409,\n",
       "  'pixel_AUROC': 0.950670599937439,\n",
       "  'pixel_F1Score': 0.7730256915092468}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 100,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: train  \n",
    "Backbone: WideResNet50_2  \n",
    "Num_features: 300    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "172       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 172 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe128cbe4a544c3a27d6cf1cf119abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d05b2123e31483d93d8fb06114e6cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.fit(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cedab24106f4b849201db615bd50ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.706804096698761     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.923828125        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9516156315803528     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7864751815795898     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.706804096698761    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.923828125       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9516156315803528    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7864751815795898    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.706804096698761,\n",
       "  'image_F1Score': 0.923828125,\n",
       "  'pixel_AUROC': 0.9516156315803528,\n",
       "  'pixel_F1Score': 0.7864751815795898}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42   \n",
    ")\n",
    "\n",
    "engine.test(model=model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: fit  \n",
    "Backbone: CSPDarknet53  \n",
    "Num_features: 300    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 27.6 M | train\n",
      "---------------------------------------------------------\n",
      "27.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 M    Total params\n",
      "110.569   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "594       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 594 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4de042cc7e5443e8066c2ed42ed6c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaa836d144547debd8ce3435a6b3d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = timm.create_model('cspdarknet53', pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/cspdarknet53.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"stages.1\", \"stages.2\", \"stages.3\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.fit(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12668989111743d4a30d2cedcea5543e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7620402574539185     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.913654625415802     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9143519401550293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6724317073822021     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7620402574539185    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.913654625415802    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9143519401550293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6724317073822021    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7620402574539185,\n",
       "  'image_F1Score': 0.913654625415802,\n",
       "  'pixel_AUROC': 0.9143519401550293,\n",
       "  'pixel_F1Score': 0.6724317073822021}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "engine.test(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: fit   \n",
    "Backbone: CSPDarknet53  \n",
    "Num_features: 100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 27.6 M | train\n",
      "---------------------------------------------------------\n",
      "27.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 M    Total params\n",
      "110.569   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "594       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 594 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0044191b41dd450bbe256c650464de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7596c3d9a4f4fb399b4382d5ce178ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa92f307d824778bf580299f49fc1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7561749815940857     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9132149815559387     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8958757519721985     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6353753805160522     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7561749815940857    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9132149815559387    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8958757519721985    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6353753805160522    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7561749815940857,\n",
       "  'image_F1Score': 0.9132149815559387,\n",
       "  'pixel_AUROC': 0.8958757519721985,\n",
       "  'pixel_F1Score': 0.6353753805160522}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = timm.create_model('cspdarknet53', pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/cspdarknet53.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"stages.1\", \"stages.2\", \"stages.3\"],\n",
    "    n_features = 100,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine function: train   \n",
    "Backbone: CSPDarknet53  \n",
    "Num_features: 400    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 27.6 M | train\n",
      "---------------------------------------------------------\n",
      "27.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 M    Total params\n",
      "110.569   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "594       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 594 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b425d180879149b7affd9ba7425d17ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ea97134a1a4a1a94a5de05908a7283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e77d4f9c5a14bb9bc2a3cd8ecb0bf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7626596689224243     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9187562465667725     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9117726683616638     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6651197075843811     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7626596689224243    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9187562465667725    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9117726683616638    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6651197075843811    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7626596689224243,\n",
       "  'image_F1Score': 0.9187562465667725,\n",
       "  'pixel_AUROC': 0.9117726683616638,\n",
       "  'pixel_F1Score': 0.6651197075843811}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = timm.create_model('cspdarknet53', pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/cspdarknet53.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"stages.1\", \"stages.2\", \"stages.3\"],\n",
    "    n_features = 400,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1168      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1168 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fcb1e910314dcf831787ebd4ac4cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7693a6074cec400990ca4ec744872e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8f6fe07877475db3761c1a93dda975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5348044633865356     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8985239863395691     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4998382031917572     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3273930549621582     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5348044633865356    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8985239863395691    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4998382031917572    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3273930549621582    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5348044633865356,\n",
       "  'image_F1Score': 0.8985239863395691,\n",
       "  'pixel_AUROC': 0.4998382031917572,\n",
       "  'pixel_F1Score': 0.3273930549621582}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.1\", \"features.2\", \"features.4\"],\n",
    "    n_features = 100,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1225      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1225 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b277e7dfbf47440d99cc5e7e2868772f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0986e4cfa3024a4dab8547a0306c2424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aa2f9af8344ae79da697e9643453e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5416182279586792     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.904411792755127     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4617898166179657     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3088890612125397     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5416182279586792    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.904411792755127    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4617898166179657    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3088890612125397    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5416182279586792,\n",
       "  'image_F1Score': 0.904411792755127,\n",
       "  'pixel_AUROC': 0.4617898166179657,\n",
       "  'pixel_F1Score': 0.3088890612125397}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.4\", \"features.6\", \"features.8\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1225      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1225 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d2848703344fbbbdbb61038b8867df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892f24e7613046c89b8c5838207c83a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c32e3df43e407fae302020919a058a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5423151254653931     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9035812616348267     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48882246017456055    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.32298916578292847    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5423151254653931    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9035812616348267    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48882246017456055   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.32298916578292847   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5423151254653931,\n",
       "  'image_F1Score': 0.9035812616348267,\n",
       "  'pixel_AUROC': 0.48882246017456055,\n",
       "  'pixel_F1Score': 0.32298916578292847}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.2\", \"features.5\", \"features.7\"],\n",
    "    n_features = 400,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1225      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1225 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af8b11510eb493db4b58a7e03796fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2d54b64d6a4bc2babf25b5f8a869ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92a6af9a0154ce0b833333db45f95d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5583043098449707     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9035812616348267     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6003789901733398     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3316190242767334     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5583043098449707    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9035812616348267    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6003789901733398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3316190242767334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5583043098449707,\n",
       "  'image_F1Score': 0.9035812616348267,\n",
       "  'pixel_AUROC': 0.6003789901733398,\n",
       "  'pixel_F1Score': 0.3316190242767334}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.6\", \"features.8\"],\n",
    "    n_features = 500,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1189      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1189 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a1808734f3493c84bc8ce0b96ec9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca768d9a676b46518168d886c0cabddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14088a7b0dbd4d80bcaad51e669c4541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5460124015808105     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9025735259056091     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4510014057159424     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31049680709838867    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5460124015808105    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9025735259056091    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4510014057159424    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31049680709838867   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5460124015808105,\n",
       "  'image_F1Score': 0.9025735259056091,\n",
       "  'pixel_AUROC': 0.4510014057159424,\n",
       "  'pixel_F1Score': 0.31049680709838867}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.7\", \"features.8\"],\n",
    "    n_features = 304,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 66.3 M | train\n",
      "---------------------------------------------------------\n",
      "66.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "66.3 M    Total params\n",
      "265.392   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "1225      Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 1225 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f610e9da9be455e9d25a4d21d601333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b4f2604e424258b6e01e3852750ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc21288b8c84a6cbfbf76c5af9d6c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5846496224403381     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9012003540992737     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6856395602226257     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3787895441055298     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5846496224403381    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9012003540992737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6856395602226257    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3787895441055298    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.5846496224403381,\n",
       "  'image_F1Score': 0.9012003540992737,\n",
       "  'pixel_AUROC': 0.6856395602226257,\n",
       "  'pixel_F1Score': 0.3787895441055298}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.7\", \"features.8\"],\n",
    "    n_features = 1000,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "import timm\n",
    "from anomalib.models.components.feature_extractors import TimmFeatureExtractor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "custom_backbone = models.efficientnet_b7(pretrained=False)\n",
    "weights = torch.load(\"/wrk/weights/efficientnet_b7.pth\", map_location='cuda')\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "        layers=[\"features.7\", \"features.8\"],\n",
    "    n_features = 1000,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "164       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 164 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3011d4e37a249fbb918288ccc9c464e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b936be1e2fd460f98db098e60aebf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e71c4983f0d4b628ee08f454e064f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7026132345199585     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9205102920532227     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9570789337158203     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8026213049888611     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7026132345199585    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9205102920532227    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9570789337158203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8026213049888611    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7026132345199585,\n",
       "  'image_F1Score': 0.9205102920532227,\n",
       "  'pixel_AUROC': 0.9570789337158203,\n",
       "  'pixel_F1Score': 0.8026213049888611}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer2\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "164       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 164 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e0dd6a8e954416b554532b92cae661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1bb764ec68405caeb1ae4896a38c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dccd49f99b74a8da93871c56c4a1ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7018582820892334     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9212598204612732     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9525946974754333     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7895775437355042     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7018582820892334    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9212598204612732    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9525946974754333    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7895775437355042    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7018582820892334,\n",
       "  'image_F1Score': 0.9212598204612732,\n",
       "  'pixel_AUROC': 0.9525946974754333,\n",
       "  'pixel_F1Score': 0.7895775437355042}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer2\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "158       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 158 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91dd1c27d944fb8a07422a9db9d798d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8ed1e356594cb4848924f9dc1cf479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ca55c252c547618739d89379d03e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6992064118385315     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9206660389900208     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9541706442832947     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7876111268997192     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6992064118385315    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9206660389900208    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9541706442832947    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7876111268997192    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.6992064118385315,\n",
       "  'image_F1Score': 0.9206660389900208,\n",
       "  'pixel_AUROC': 0.9541706442832947,\n",
       "  'pixel_F1Score': 0.7876111268997192}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\"],\n",
    "    n_features = 256,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local weights loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 68.9 M | train\n",
      "---------------------------------------------------------\n",
      "68.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.9 M    Total params\n",
      "275.533   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "172       Modules in eval mode\n",
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 172 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4889d3ec6374b959eaad8d61e2368c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0f7b28b63141ef8a10e85cf2f6d021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeab9f04b532408ab39430ffd0e5d363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7572396397590637     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9120000004768372     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9505519866943359     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7810545563697815     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7572396397590637    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9120000004768372    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9505519866943359    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7810545563697815    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 0.7572396397590637,\n",
       "  'image_F1Score': 0.9120000004768372,\n",
       "  'pixel_AUROC': 0.9505519866943359,\n",
       "  'pixel_F1Score': 0.7810545563697815}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anomalib.engine import Engine\n",
    "import torch\n",
    "from anomalib.models.image.padim import Padim\n",
    "from safetensors.torch import load_file\n",
    "from torchvision import models\n",
    "import os\n",
    "from anomalib.data import Folder\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "train_dataset = Folder(\n",
    "    name=\"custom_folder\",\n",
    "    root=\"/wrk/data/processed\",\n",
    "    normal_dir=\"normal_dir\",\n",
    "    abnormal_dir=\"abnormal_dir\",\n",
    "    mask_dir=\"mask_dir\",\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_workers=2,\n",
    "    seed=42    \n",
    ")\n",
    "\n",
    "weights = torch.load(\"/wrk/weights/wide_resnet50_2.pth\", map_location='cuda')\n",
    "custom_backbone = models.wide_resnet50_2()\n",
    "custom_backbone.load_state_dict(weights)\n",
    "custom_backbone.eval()\n",
    "\n",
    "if custom_backbone:\n",
    "    print(\"Local weights loaded successfully\")\n",
    "\n",
    "model = Padim(\n",
    "    backbone=custom_backbone,\n",
    "    layers=[\"layer1\", \"layer3\"],\n",
    "    n_features = 300,\n",
    "    pre_trained=False\n",
    ")\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "engine = Engine(\n",
    "                accelerator='cuda', \n",
    "                enable_progress_bar=True\n",
    "                )\n",
    "\n",
    "engine.train(model=model, datamodule=train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
